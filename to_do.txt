* find another way to save best model (loss is not fit for the task)

* optimize GPU memory utilization

* create tests.csv file and read from there

* calculate and save runtimes

* add sources in each file.py

* run steps.odt file starting for everything done
    - double DQN implementation
    - rewards tried
    - architecture modified (compared to source x)
    - 
